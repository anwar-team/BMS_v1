# -*- coding: utf-8 -*-
"""
Enhanced Shamela Runner Optimized - ุณูุฑุจุช ุชุดุบูู ูุญุณู ููููุชุจุฉ ุงูุดุงููุฉ
ูุฌูุน ุฌููุน ุงููุธุงุฆู ุงููุญุณูุฉ ูู ูุงุฌูุฉ ูุงุญุฏุฉ ุณููุฉ ุงูุงุณุชุฎุฏุงู ูุน ุชุญุณููุงุช ุงูุฃุฏุงุก

ุงูููุฒุงุช ุงููุญุณูุฉ:
- ุงุณุชุฎุฑุงุฌ ุงููุชุจ ูุน ุฌููุน ุงูุชุญุณููุงุช ูุงูุชูุงุฒู
- ุญูุธ ุงูุจูุงูุงุช ูู ูุงุนุฏุฉ ุงูุจูุงูุงุช ุงููุญุณูุฉ ูุน Batch Processing
- ุฅูุดุงุก ุชูุงุฑูุฑ ุดุงููุฉ
- ูุนุงูุฌุฉ ุงูุฃุฎุทุงุก ุงููุญุณูุฉ
- ูุธุงู ุงูุงุณุชุฆูุงู ุงูุขูู
- ุชุญุณููุงุช ุงูุฐุงูุฑุฉ ูุงูุฃุฏุงุก
"""

import os
import sys
import json
import logging
import argparse
import hashlib
from datetime import datetime
from pathlib import Path
from logging.handlers import RotatingFileHandler
from typing import Dict, Any, Optional

# ุฅุถุงูุฉ ุงููุฌูุฏ ุงูุญุงูู ููู path
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, current_dir)

try:
    from enhanced_shamela_scraper_optimized import (
        scrape_enhanced_book, save_enhanced_book_to_json,
        OptimizationConfig as ScraperConfig
    )
    from enhanced_database_manager_optimized import (
        EnhancedShamelaDatabaseManagerOptimized
    )
except ImportError:
    # Fallback to original versions if optimized not available
    try:
        from enhanced_shamela_scraper import scrape_enhanced_book, save_enhanced_book_to_json
        from enhanced_database_manager import EnhancedShamelaDatabaseManager as EnhancedShamelaDatabaseManagerOptimized
        ScraperConfig = None
        DatabaseConfig = None
    except ImportError as e:
        print(f"ุฎุทุฃ ูู ุงุณุชูุฑุงุฏ ุงููุญุฏุงุช: {e}")
        print("ุชุฃูุฏ ูู ูุฌูุฏ ูููุงุช enhanced_shamela_scraper.py ู enhanced_database_manager.py")
        sys.exit(1)

# ุฅุนุฏุงุฏ ุงูุชุณุฌูู ุงููุญุณู
def setup_optimized_logging(log_level: str = 'INFO', max_bytes: int = 10*1024*1024, backup_count: int = 5):
    """ุฅุนุฏุงุฏ ูุธุงู ุงูุชุณุฌูู ุงููุญุณู ูุน RotatingFileHandler"""
    logger = logging.getLogger()
    logger.setLevel(getattr(logging, log_level.upper()))
    
    # ุฅุฒุงูุฉ ุงููุนุงูุฌุงุช ุงูููุฌูุฏุฉ
    for handler in logger.handlers[:]:
        logger.removeHandler(handler)
    
    # ูุนุงูุฌ ุงูููู ุงูุฏูุงุฑ
    file_handler = RotatingFileHandler(
        'enhanced_shamela_runner_optimized.log',
        maxBytes=max_bytes,
        backupCount=backup_count,
        encoding='utf-8'
    )
    file_handler.setLevel(getattr(logging, log_level.upper()))
    
    # ูุนุงูุฌ ูุญุฏุฉ ุงูุชุญูู
    console_handler = logging.StreamHandler()
    console_handler.setLevel(logging.INFO)
    
    # ุชูุณูู ุงูุณุฌูุงุช
    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
    file_handler.setFormatter(formatter)
    console_handler.setFormatter(formatter)
    
    logger.addHandler(file_handler)
    logger.addHandler(console_handler)
    
    return logger

logger = setup_optimized_logging()

def print_header():
    """ุทุจุงุนุฉ ุฑุฃุณ ุงูุจุฑูุงูุฌ"""
    print("=" * 60)
    print("ุณูุฑุจุช ุงูููุชุจุฉ ุงูุดุงููุฉ ุงููุญุณู - ุงูุฅุตุฏุงุฑ ุงููุทูุฑ")
    print("Enhanced Shamela Scraper - Optimized Version")
    print("=" * 60)
    print()

def print_separator():
    """ุทุจุงุนุฉ ูุงุตู"""
    print("-" * 60)

def create_checkpoint_file(book_id: str, progress_data: Dict[str, Any]) -> str:
    """ุฅูุดุงุก ููู ููุทุฉ ุชูุชูุด ููุงุณุชุฆูุงู ุงูุขูู"""
    checkpoint_dir = os.path.join(current_dir, "checkpoints")
    os.makedirs(checkpoint_dir, exist_ok=True)
    
    checkpoint_file = os.path.join(checkpoint_dir, f"checkpoint_{book_id}.json")
    
    with open(checkpoint_file, 'w', encoding='utf-8') as f:
        json.dump(progress_data, f, ensure_ascii=False, indent=2)
    
    return checkpoint_file

def load_checkpoint_file(book_id: str) -> Optional[Dict[str, Any]]:
    """ุชุญููู ููู ููุทุฉ ุงูุชูุชูุด"""
    checkpoint_file = os.path.join(current_dir, "checkpoints", f"checkpoint_{book_id}.json")
    
    if os.path.exists(checkpoint_file):
        try:
            with open(checkpoint_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            logger.warning(f"ูุดู ูู ุชุญููู ููุทุฉ ุงูุชูุชูุด: {e}")
    
    return None

def calculate_content_hash(content: str) -> str:
    """ุญุณุงุจ hash ูููุญุชูู ููุชุญูู ูู ุงูุชุทุงุจู"""
    return hashlib.sha256(content.encode('utf-8')).hexdigest()

def extract_book_full_optimized(book_id: str, max_pages: int = None, output_dir: str = None, 
                               optimization_config: Dict[str, Any] = None) -> dict:
    """
    ุงุณุชุฎุฑุงุฌ ูุชุงุจ ูุงูู ูุน ุฌููุน ุงูุชุญุณููุงุช
    """
    print(f"๐ ุจุฏุก ุงุณุชุฎุฑุงุฌ ุงููุชุงุจ ุงููุญุณู: {book_id}")
    print_separator()
    
    try:
        # ุฅุนุฏุงุฏ ุงูุชูููู ุงููุญุณู
        config = optimization_config or {}
        
        # ุชุญูู ูู ูุฌูุฏ ููุทุฉ ุชูุชูุด ููุงุณุชุฆูุงู
        checkpoint_data = None
        if config.get('resume', False):
            checkpoint_data = load_checkpoint_file(book_id)
            if checkpoint_data:
                print(f"๐ ุชู ุงูุนุซูุฑ ุนูู ููุทุฉ ุชูุชูุดุ ุงูุงุณุชุฆูุงู ูู ุงูุตูุญุฉ {checkpoint_data.get('last_page', 0)}")
        
        # ุฅุนุฏุงุฏ ูููููุบ ุงูุงุณุชุฎุฑุงุฌ
        scraper_config = None
        if ScraperConfig:
            scraper_config = ScraperConfig(
                max_workers=config.get('max_workers', 4),
                rate_limit=config.get('rate', 2.0),
                timeout=config.get('timeout', 30),
                retries=config.get('retries', 3),
                chunk_size=config.get('chunk_size', 100),
                stream_json=config.get('stream_json', False),
                resume=checkpoint_data is not None,
                skip_existing=config.get('skip_existing', False)
            )
        
        # ุงุณุชุฎุฑุงุฌ ุงููุชุงุจ
        print("๐ ุงุณุชุฎุฑุงุฌ ุจูุงูุงุช ุงููุชุงุจ...")
        if scraper_config:
            book = scrape_enhanced_book(book_id, max_pages=max_pages, 
                                      extract_content=True, config=scraper_config)
        else:
            book = scrape_enhanced_book(book_id, max_pages=max_pages, extract_content=True)
        
        # ุชุญุฏูุฏ ูุฌูุฏ ุงูุฅุฎุฑุงุฌ
        if not output_dir:
            output_dir = os.path.join(current_dir, "enhanced_books_optimized")
        
        os.makedirs(output_dir, exist_ok=True)
        
        # ุฅูุดุงุก ุงุณู ุงูููู
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"enhanced_book_{book_id}_{timestamp}.json"
        output_path = os.path.join(output_dir, filename)
        
        # ุญูุธ ุงููุชุงุจ
        print("๐พ ุญูุธ ุงูุจูุงูุงุช...")
        if config.get('stream_json', False):
            # ุงุณุชุฎุฏุงู ุงูุญูุธ ุงููุญุณู ููุฐุงูุฑุฉ
            save_enhanced_book_to_json(book, output_path, stream=True)
        else:
            save_enhanced_book_to_json(book, output_path)
        
        # ุฅูุดุงุก ููุทุฉ ุชูุชูุด ููุงุฆูุฉ
        if config.get('resume', False):
            final_checkpoint = {
                'book_id': book_id,
                'status': 'completed',
                'total_pages': len(book.pages) if book.pages else 0,
                'completion_time': datetime.now().isoformat(),
                'output_file': output_path
            }
            create_checkpoint_file(book_id, final_checkpoint)
        
        # ุทุจุงุนุฉ ุงููุชุงุฆุฌ
        print("\nโ ุชู ุงุณุชุฎุฑุงุฌ ุงููุชุงุจ ุจูุฌุงุญ!")
        print_separator()
        print(f"๐ ุงูุนููุงู: {book.title}")
        print(f"๐จโ๐ ุงููุคูู(ูู): {', '.join(author.name for author in book.authors)}")
        
        if book.publisher:
            print(f"๐ข ุงููุงุดุฑ: {book.publisher.name}")
            if book.publisher.location:
                print(f"๐ ุงููููุน: {book.publisher.location}")
        
        if book.book_section:
            print(f"๐ ุงููุณู: {book.book_section.name}")
        
        if book.edition:
            edition_info = f"๐ ุงูุทุจุนุฉ: {book.edition}"
            if book.edition_number:
                edition_info += f" (ุฑูู: {book.edition_number})"
            print(edition_info)
        
        print(f"๐ ุนุฏุฏ ุงูุตูุญุงุช: {len(book.pages) if book.pages else 0}")
        print(f"๐ ุนุฏุฏ ุงููุตูู: {len(book.index) if book.index else 0}")
        print(f"๐ ุนุฏุฏ ุงูุฃุฌุฒุงุก: {len(book.volumes) if book.volumes else 0}")
        print(f"๐พ ุญููุธ ูู: {output_path}")
        
        return {
            'success': True,
            'book_id': book_id,
            'title': book.title,
            'authors': [author.name for author in book.authors],
            'total_pages': len(book.pages) if book.pages else 0,
            'total_chapters': len(book.index) if book.index else 0,
            'total_volumes': len(book.volumes) if book.volumes else 0,
            'output_file': output_path,
            'extraction_time': datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"ุฎุทุฃ ูู ุงุณุชุฎุฑุงุฌ ุงููุชุงุจ: {e}")
        print(f"โ ุฎุทุฃ ูู ุงุณุชุฎุฑุงุฌ ุงููุชุงุจ: {e}")
        return {
            'success': False,
            'error': str(e),
            'book_id': book_id
        }

def save_to_database_optimized(json_path: str, db_config: dict, 
                              optimization_config: Dict[str, Any] = None) -> dict:
    """
    ุญูุธ ููู JSON ูู ูุงุนุฏุฉ ุงูุจูุงูุงุช ูุน ุงูุชุญุณููุงุช
    """
    print(f"๐พ ุจุฏุก ุญูุธ ุงูุจูุงูุงุช ูู ูุงุนุฏุฉ ุงูุจูุงูุงุช: {json_path}")
    print_separator()
    
    try:
        # ุฅุนุฏุงุฏ ุงูุชูููู ุงููุญุณู
        config = optimization_config or {}
        
        # ุฅุนุฏุงุฏ ูููููุบ ูุงุนุฏุฉ ุงูุจูุงูุงุช
        from enhanced_database_manager_optimized import OptimizationConfig as DatabaseOptimizationConfig
        db_optimization_config = DatabaseOptimizationConfig(
            batch_size=config.get('batch_size', 500),
            pool_size=config.get('connection_pool_size', 5),
            prepared_statements=True,
            fast_bulk=config.get('fast_bulk', False),
            commit_interval=config.get('commit_interval', 1000)
        )
        
        # ุงูุงุชุตุงู ุจูุงุนุฏุฉ ุงูุจูุงูุงุช
        if db_optimization_config:
            db_manager = EnhancedShamelaDatabaseManagerOptimized(db_config, db_optimization_config)
        else:
            db_manager = EnhancedShamelaDatabaseManagerOptimized(db_config)
        
        db_manager.connect()
        
        # ุชุญููู ูุญูุธ ุงููุชุงุจ
        print("๐ ุชุญููู ุจูุงูุงุช ุงููุชุงุจ ูู JSON...")
        book = db_manager.load_enhanced_book_from_json(json_path)
        
        print("๐พ ุญูุธ ุงููุชุงุจ ูู ูุงุนุฏุฉ ุงูุจูุงูุงุช...")
        book_id = db_manager.save_complete_enhanced_book(book)
        
        # ุงูุญุตูู ุนูู ุฅุญุตุงุฆูุงุช ุงูุฃุฏุงุก
        if hasattr(db_manager, 'get_performance_stats'):
            stats = db_manager.get_performance_stats()
            print("\n๐ ุฅุญุตุงุฆูุงุช ุงูุฃุฏุงุก:")
            print(f"   - ุฅุฌูุงูู ุงูุงุณุชุนูุงูุงุช: {stats.get('total_queries', 0)}")
            print(f"   - ุนูููุงุช ุงูุฅุฏุฑุงุฌ ุงููุฌูุนุฉ: {stats.get('batch_inserts', 0)}")
            print(f"   - ูุฌุงุญุงุช ุงูุชุฎุฒูู ุงููุคูุช: {stats.get('cache_hits', 0)}")
            print(f"   - ุฅุฎูุงูุงุช ุงูุชุฎุฒูู ุงููุคูุช: {stats.get('cache_misses', 0)}")
        
        db_manager.disconnect()
        
        print(f"\nโ ุชู ุญูุธ ุงููุชุงุจ ุจูุฌุงุญ! (ID: {book_id})")
        
        return {
            'success': True,
            'book_id': book_id,
            'title': book.title,
            'database_id': book_id,
            'save_time': datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"ุฎุทุฃ ูู ุญูุธ ุงูุจูุงูุงุช: {e}")
        print(f"โ ุฎุทุฃ ูู ุญูุธ ุงูุจูุงูุงุช: {e}")
        return {
            'success': False,
            'error': str(e),
            'json_file': json_path
        }

def extract_and_save_book_optimized(book_id: str, max_pages: int = None, 
                                   db_config: dict = None, output_dir: str = None,
                                   optimization_config: Dict[str, Any] = None) -> dict:
    """
    ุงุณุชุฎุฑุงุฌ ูุญูุธ ูุชุงุจ ูุงูู ูุน ุฌููุน ุงูุชุญุณููุงุช
    """
    print_header()
    
    # ุงุณุชุฎุฑุงุฌ ุงููุชุงุจ
    extract_result = extract_book_full_optimized(book_id, max_pages, output_dir, optimization_config)
    
    if not extract_result['success']:
        return extract_result
    
    # ุญูุธ ูู ูุงุนุฏุฉ ุงูุจูุงูุงุช ุฅุฐุง ุชู ุชุญุฏูุฏ ุงูุฅุนุฏุงุฏุงุช
    if db_config:
        print_separator()
        save_result = save_to_database_optimized(extract_result['output_file'], db_config, optimization_config)
        
        if save_result['success']:
            extract_result.update({
                'database_id': save_result['book_id'],
                'database_save_time': save_result['save_time']
            })
        else:
            extract_result['database_error'] = save_result['error']
    
    return extract_result

def create_database_tables_optimized(db_config: dict, optimization_config: Dict[str, Any] = None) -> dict:
    """
    ุฅูุดุงุก ุฌุฏุงูู ูุงุนุฏุฉ ุงูุจูุงูุงุช ูุน ุงูููุงุฑุณ ุงููุญุณูุฉ
    """
    print("๐ง ุฅูุดุงุก ุฌุฏุงูู ูุงุนุฏุฉ ุงูุจูุงูุงุช...")
    print_separator()
    
    try:
        config = optimization_config or {}
        
        # ุฅุนุฏุงุฏ ูููููุบ ูุงุนุฏุฉ ุงูุจูุงูุงุช
        from enhanced_database_manager_optimized import OptimizationConfig as DatabaseOptimizationConfig
        db_optimization_config = DatabaseOptimizationConfig(
            batch_size=config.get('batch_size', 500),
            pool_size=config.get('connection_pool_size', 5),
            prepared_statements=True,
            fast_bulk=config.get('fast_bulk', False)
        )
        
        if db_optimization_config:
            db_manager = EnhancedShamelaDatabaseManagerOptimized(db_config, db_optimization_config)
        else:
            db_manager = EnhancedShamelaDatabaseManagerOptimized(db_config)
        
        db_manager.connect()
        
        # ุฅูุดุงุก ุงูุฌุฏุงูู
        print("๐ ุฅูุดุงุก ุงูุฌุฏุงูู ุงูุฃุณุงุณูุฉ...")
        db_manager.create_tables()
        
        # ุฅูุดุงุก ุงูููุงุฑุณ ุงููุญุณูุฉ
        if hasattr(db_manager, 'create_optimized_indexes'):
            print("๐ ุฅูุดุงุก ุงูููุงุฑุณ ุงููุญุณูุฉ...")
            db_manager.create_optimized_indexes()
        
        db_manager.disconnect()
        
        print("\nโ ุชู ุฅูุดุงุก ุฌุฏุงูู ูุงุนุฏุฉ ุงูุจูุงูุงุช ุจูุฌุงุญ!")
        
        return {
            'success': True,
            'message': 'ุชู ุฅูุดุงุก ุงูุฌุฏุงูู ูุงูููุงุฑุณ ุจูุฌุงุญ',
            'creation_time': datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"ุฎุทุฃ ูู ุฅูุดุงุก ุงูุฌุฏุงูู: {e}")
        print(f"โ ุฎุทุฃ ูู ุฅูุดุงุก ุงูุฌุฏุงูู: {e}")
        return {
            'success': False,
            'error': str(e)
        }

def get_database_stats_optimized(book_id: int, db_config: dict, 
                                 optimization_config: Dict[str, Any] = None) -> dict:
    """
    ุนุฑุถ ุฅุญุตุงุฆูุงุช ูุชุงุจ ูู ูุงุนุฏุฉ ุงูุจูุงูุงุช ูุน ุชุญุณููุงุช ุงูุฃุฏุงุก
    """
    print(f"๐ ุฌูุจ ุฅุญุตุงุฆูุงุช ุงููุชุงุจ: {book_id}")
    print_separator()
    
    try:
        config = optimization_config or {}
        
        # ุฅุนุฏุงุฏ ูููููุบ ูุงุนุฏุฉ ุงูุจูุงูุงุช
        from enhanced_database_manager_optimized import OptimizationConfig as DatabaseOptimizationConfig
        db_optimization_config = DatabaseOptimizationConfig(
            pool_size=config.get('connection_pool_size', 5),
            prepared_statements=True
        )
        
        if db_optimization_config:
            db_manager = EnhancedShamelaDatabaseManagerOptimized(db_config, db_optimization_config)
        else:
            db_manager = EnhancedShamelaDatabaseManagerOptimized(db_config)
        
        db_manager.connect()
        
        # ุฌูุจ ูุนูููุงุช ุงููุชุงุจ ุงูุฃุณุงุณูุฉ
        book_query = """
        SELECT b.id, b.title, b.shamela_id, b.total_pages, b.total_volumes,
               p.name as publisher_name, bs.name as section_name
        FROM books b
        LEFT JOIN publishers p ON b.publisher_id = p.id
        LEFT JOIN book_sections bs ON b.book_section_id = bs.id
        WHERE b.id = %s
        """
        
        cursor = db_manager.connection.cursor(dictionary=True)
        cursor.execute(book_query, (book_id,))
        book_info = cursor.fetchone()
        
        if not book_info:
            return {
                'success': False,
                'error': f'ุงููุชุงุจ ุบูุฑ ููุฌูุฏ: {book_id}'
            }
        
        # ุฌูุจ ุฅุญุตุงุฆูุงุช ุงููุคูููู
        authors_query = """
        SELECT a.name, a.death_year
        FROM authors a
        JOIN author_book ab ON a.id = ab.author_id
        WHERE ab.book_id = %s
        """
        cursor.execute(authors_query, (book_id,))
        authors = cursor.fetchall()
        
        # ุฌูุจ ุฅุญุตุงุฆูุงุช ุงูุฃุฌุฒุงุก
        volumes_query = """
        SELECT COUNT(*) as volume_count, 
               SUM(page_count) as total_volume_pages
        FROM volumes 
        WHERE book_id = %s
        """
        cursor.execute(volumes_query, (book_id,))
        volume_stats = cursor.fetchone()
        
        # ุฌูุจ ุฅุญุตุงุฆูุงุช ุงููุตูู
        chapters_query = """
        SELECT COUNT(*) as chapter_count,
               AVG(CHAR_LENGTH(title)) as avg_title_length
        FROM chapters 
        WHERE book_id = %s
        """
        cursor.execute(chapters_query, (book_id,))
        chapter_stats = cursor.fetchone()
        
        # ุฌูุจ ุฅุญุตุงุฆูุงุช ุงูุตูุญุงุช
        pages_query = """
        SELECT COUNT(*) as page_count,
               AVG(CHAR_LENGTH(content)) as avg_content_length,
               SUM(CASE WHEN content IS NOT NULL AND content != '' THEN 1 ELSE 0 END) as pages_with_content,
               MIN(page_number) as min_page_number,
               MAX(page_number) as max_page_number
        FROM pages 
        WHERE book_id = %s
        """
        cursor.execute(pages_query, (book_id,))
        page_stats = cursor.fetchone()
        
        cursor.close()
        db_manager.disconnect()
        
        # ุทุจุงุนุฉ ุงูุฅุญุตุงุฆูุงุช
        print("๐ ูุนูููุงุช ุงููุชุงุจ:")
        print(f"   ุงูุนููุงู: {book_info['title']}")
        print(f"   ูุนุฑู ุงูุดุงููุฉ: {book_info['shamela_id']}")
        if book_info['publisher_name']:
            print(f"   ุงููุงุดุฑ: {book_info['publisher_name']}")
        if book_info['section_name']:
            print(f"   ุงููุณู: {book_info['section_name']}")
        
        print("\n๐จโ๐ ุงููุคูููู:")
        for author in authors:
            author_info = f"   - {author['name']}"
            if author['death_year']:
                author_info += f" (ุช. {author['death_year']})"
            print(author_info)
        
        print("\n๐ ุงูุฅุญุตุงุฆูุงุช:")
        print(f"   ุนุฏุฏ ุงูุฃุฌุฒุงุก: {volume_stats['volume_count'] or 0}")
        print(f"   ุฅุฌูุงูู ุตูุญุงุช ุงูุฃุฌุฒุงุก: {volume_stats['total_volume_pages'] or 0}")
        print(f"   ุนุฏุฏ ุงููุตูู: {chapter_stats['chapter_count'] or 0}")
        if chapter_stats['avg_title_length']:
            print(f"   ูุชูุณุท ุทูู ุนููุงู ุงููุตู: {int(chapter_stats['avg_title_length'])} ุญุฑู")
        
        print(f"   ุนุฏุฏ ุงูุตูุญุงุช: {page_stats['page_count'] or 0}")
        print(f"   ุงูุตูุญุงุช ุงูุชู ุชุญุชูู ุนูู ูุญุชูู: {page_stats['pages_with_content'] or 0}")
        if page_stats['avg_content_length']:
            print(f"   ูุชูุณุท ุทูู ุงููุญุชูู: {int(page_stats['avg_content_length'])} ุญุฑู")
        if page_stats['min_page_number'] and page_stats['max_page_number']:
            print(f"   ูุทุงู ุฃุฑูุงู ุงูุตูุญุงุช: {page_stats['min_page_number']} - {page_stats['max_page_number']}")
        
        return {
            'success': True,
            'book_info': dict(book_info),
            'authors': [dict(author) for author in authors],
            'volume_stats': dict(volume_stats),
            'chapter_stats': dict(chapter_stats),
            'page_stats': dict(page_stats),
            'stats_time': datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"ุฎุทุฃ ูู ุฌูุจ ุงูุฅุญุตุงุฆูุงุช: {e}")
        print(f"โ ุฎุทุฃ ูู ุฌูุจ ุงูุฅุญุตุงุฆูุงุช: {e}")
        return {
            'success': False,
            'error': str(e),
            'book_id': book_id
        }

def run_parity_check(book_id: str, max_pages: int = None) -> dict:
    """
    ุชุดุบูู ูุญุต ุงูุชุทุงุจู ุจูู ุงููุณุฎุฉ ุงูุฃุตููุฉ ูุงููุญุณูุฉ
    """
    print(f"๐ ุจุฏุก ูุญุต ุงูุชุทุงุจู ูููุชุงุจ: {book_id}")
    print_separator()
    
    try:
        # ุงุณุชุฎุฑุงุฌ ุจุงุณุชุฎุฏุงู ุงููุณุฎุฉ ุงูุฃุตููุฉ
        print("๐ ุงุณุชุฎุฑุงุฌ ุจุงุณุชุฎุฏุงู ุงููุณุฎุฉ ุงูุฃุตููุฉ...")
        from enhanced_shamela_scraper import scrape_enhanced_book as original_scrape
        original_book = original_scrape(book_id, max_pages=max_pages, extract_content=True)
        
        # ุงุณุชุฎุฑุงุฌ ุจุงุณุชุฎุฏุงู ุงููุณุฎุฉ ุงููุญุณูุฉ
        print("โก ุงุณุชุฎุฑุงุฌ ุจุงุณุชุฎุฏุงู ุงููุณุฎุฉ ุงููุญุณูุฉ...")
        optimized_book = scrape_enhanced_book(book_id, max_pages=max_pages, extract_content=True)
        
        # ููุงุฑูุฉ ุงููุชุงุฆุฌ
        print("๐ ููุงุฑูุฉ ุงููุชุงุฆุฌ...")
        
        differences = []
        
        # ููุงุฑูุฉ ุงููุนูููุงุช ุงูุฃุณุงุณูุฉ
        if original_book.title != optimized_book.title:
            differences.append(f"ุงูุนููุงู ูุฎุชูู: '{original_book.title}' vs '{optimized_book.title}'")
        
        if len(original_book.authors) != len(optimized_book.authors):
            differences.append(f"ุนุฏุฏ ุงููุคูููู ูุฎุชูู: {len(original_book.authors)} vs {len(optimized_book.authors)}")
        
        if len(original_book.pages or []) != len(optimized_book.pages or []):
            differences.append(f"ุนุฏุฏ ุงูุตูุญุงุช ูุฎุชูู: {len(original_book.pages or [])} vs {len(optimized_book.pages or [])}")
        
        # ููุงุฑูุฉ ุงููุตูู (ุงููุณุฎุฉ ุงูุฃุตููุฉ ุชุณุชุฎุฏู indexุ ุงููุญุณูุฉ ุชุณุชุฎุฏู index ุฃูุถุงู)
        original_chapters = getattr(original_book, 'index', []) or getattr(original_book, 'chapters', [])
        optimized_chapters = getattr(optimized_book, 'index', []) or getattr(optimized_book, 'chapters', [])
        
        if len(original_chapters) != len(optimized_chapters):
            differences.append(f"ุนุฏุฏ ุงููุตูู ูุฎุชูู: {len(original_chapters)} vs {len(optimized_chapters)}")
        
        if len(original_book.volumes or []) != len(optimized_book.volumes or []):
            differences.append(f"ุนุฏุฏ ุงูุฃุฌุฒุงุก ูุฎุชูู: {len(original_book.volumes or [])} vs {len(optimized_book.volumes or [])}")
        
        # ููุงุฑูุฉ ูุญุชูู ุงูุตูุญุงุช
        if original_book.pages and optimized_book.pages:
            for i, (orig_page, opt_page) in enumerate(zip(original_book.pages, optimized_book.pages)):
                if orig_page.page_number != opt_page.page_number:
                    differences.append(f"ุฑูู ุงูุตูุญุฉ {i+1} ูุฎุชูู: {orig_page.page_number} vs {opt_page.page_number}")
                
                if orig_page.internal_index != opt_page.internal_index:
                    differences.append(f"ุงูููุฑุณ ุงูุฏุงุฎูู ููุตูุญุฉ {i+1} ูุฎุชูู: {orig_page.internal_index} vs {opt_page.internal_index}")
                
                if orig_page.content != opt_page.content:
                    orig_hash = calculate_content_hash(orig_page.content or "")
                    opt_hash = calculate_content_hash(opt_page.content or "")
                    if orig_hash != opt_hash:
                        differences.append(f"ูุญุชูู ุงูุตูุญุฉ {i+1} ูุฎุชูู (hash ูุฎุชูู)")
        
        # ุงููุชูุฌุฉ
        if differences:
            print("โ ูุดู ูุญุต ุงูุชุทุงุจู!")
            print("ุงูุงุฎุชูุงูุงุช ุงูููุชุดูุฉ:")
            for diff in differences:
                print(f"   - {diff}")
            
            return {
                'success': False,
                'parity_check': False,
                'differences': differences,
                'book_id': book_id
            }
        else:
            print("โ ูุฌุญ ูุญุต ุงูุชุทุงุจู! ุงููุชุงุฆุฌ ูุชุทุงุจูุฉ ุชูุงูุงู.")
            
            return {
                'success': True,
                'parity_check': True,
                'message': 'ุงููุชุงุฆุฌ ูุชุทุงุจูุฉ ุชูุงูุงู ุจูู ุงููุณุฎุฉ ุงูุฃุตููุฉ ูุงููุญุณูุฉ',
                'book_id': book_id,
                'check_time': datetime.now().isoformat()
            }
    
    except Exception as e:
        logger.error(f"ุฎุทุฃ ูู ูุญุต ุงูุชุทุงุจู: {e}")
        print(f"โ ุฎุทุฃ ูู ูุญุต ุงูุชุทุงุจู: {e}")
        return {
            'success': False,
            'error': str(e),
            'book_id': book_id
        }

def main():
    """
    ุงููุธููุฉ ุงูุฑุฆูุณูุฉ ููุณูุฑุจุช ุงููุญุณู
    """
    parser = argparse.ArgumentParser(
        description="ุณูุฑุจุช ุงูููุชุจุฉ ุงูุดุงููุฉ ุงููุญุณู - ุงุณุชุฎุฑุงุฌ ูุญูุธ ุงููุชุจ ูุน ุฌููุน ุงูุชุญุณููุงุช",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ุฃูุซูุฉ ุงูุงุณุชุฎุฏุงู:

1. ุงุณุชุฎุฑุงุฌ ูุชุงุจ ูุน ุงูุชุญุณููุงุช:
   python enhanced_runner_optimized.py extract 12106 --max-workers 8 --rate 3.0

2. ุงุณุชุฎุฑุงุฌ ูุชุงุจ ูุญูุธู ูู ูุงุนุฏุฉ ุงูุจูุงูุงุช ูุน ุงูุชุญุณููุงุช:
   python enhanced_runner_optimized.py extract 12106 --db-host localhost --db-user root --db-password secret --db-name bms --batch-size 1000 --fast-bulk

3. ุญูุธ ููู JSON ููุฌูุฏ ูู ูุงุนุฏุฉ ุงูุจูุงูุงุช ูุน ุงูุชุญุณููุงุช:
   python enhanced_runner_optimized.py save-db enhanced_book_12106.json --db-host localhost --db-user root --db-password secret --db-name bms --batch-size 1000

4. ุฅูุดุงุก ุฌุฏุงูู ูุงุนุฏุฉ ุงูุจูุงูุงุช ูุน ุงูููุงุฑุณ ุงููุญุณูุฉ:
   python enhanced_runner_optimized.py create-tables --db-host localhost --db-user root --db-password secret --db-name bms

5. ุนุฑุถ ุฅุญุตุงุฆูุงุช ูุชุงุจ ูู ูุงุนุฏุฉ ุงูุจูุงูุงุช:
   python enhanced_runner_optimized.py stats 123 --db-host localhost --db-user root --db-password secret --db-name bms

6. ูุญุต ุงูุชุทุงุจู ุจูู ุงููุณุฎุฉ ุงูุฃุตููุฉ ูุงููุญุณูุฉ:
   python enhanced_runner_optimized.py parity-check 12106 --max-pages 50

7. ุงุณุชุฎุฑุงุฌ ูุน ุงูุงุณุชุฆูุงู ุงูุขูู:
   python enhanced_runner_optimized.py extract 12106 --resume --skip-existing
        """
    )
    
    subparsers = parser.add_subparsers(dest='command', help='ุงูุฃูุงูุฑ ุงููุชุงุญุฉ')
    
    # ุฃูุฑ ุงูุงุณุชุฎุฑุงุฌ
    extract_parser = subparsers.add_parser('extract', help='ุงุณุชุฎุฑุงุฌ ูุชุงุจ ูู ุงูููุชุจุฉ ุงูุดุงููุฉ')
    extract_parser.add_argument('book_id', help='ูุนุฑู ุงููุชุงุจ ูู ุงูููุชุจุฉ ุงูุดุงููุฉ')
    extract_parser.add_argument('--max-pages', type=int, help='ุงูุนุฏุฏ ุงูุฃูุตู ููุตูุญุงุช')
    extract_parser.add_argument('--output-dir', help='ูุฌูุฏ ุงูุฅุฎุฑุงุฌ')
    
    # ุฃูุฑ ุงูุญูุธ ูู ูุงุนุฏุฉ ุงูุจูุงูุงุช
    save_parser = subparsers.add_parser('save-db', help='ุญูุธ ููู JSON ูู ูุงุนุฏุฉ ุงูุจูุงูุงุช')
    save_parser.add_argument('json_file', help='ูุณุงุฑ ููู JSON')
    
    # ุฃูุฑ ุฅูุดุงุก ุงูุฌุฏุงูู
    tables_parser = subparsers.add_parser('create-tables', help='ุฅูุดุงุก ุฌุฏุงูู ูุงุนุฏุฉ ุงูุจูุงูุงุช')
    
    # ุฃูุฑ ุงูุฅุญุตุงุฆูุงุช
    stats_parser = subparsers.add_parser('stats', help='ุนุฑุถ ุฅุญุตุงุฆูุงุช ูุชุงุจ ูู ูุงุนุฏุฉ ุงูุจูุงูุงุช')
    stats_parser.add_argument('book_id', type=int, help='ูุนุฑู ุงููุชุงุจ ูู ูุงุนุฏุฉ ุงูุจูุงูุงุช')
    
    # ุฃูุฑ ูุญุต ุงูุชุทุงุจู
    parity_parser = subparsers.add_parser('parity-check', help='ูุญุต ุงูุชุทุงุจู ุจูู ุงููุณุฎุฉ ุงูุฃุตููุฉ ูุงููุญุณูุฉ')
    parity_parser.add_argument('book_id', help='ูุนุฑู ุงููุชุงุจ ูู ุงูููุชุจุฉ ุงูุดุงููุฉ')
    parity_parser.add_argument('--max-pages', type=int, help='ุงูุนุฏุฏ ุงูุฃูุตู ููุตูุญุงุช ูููุญุต')
    
    # ุฅุนุฏุงุฏุงุช ูุงุนุฏุฉ ุงูุจูุงูุงุช (ูุดุชุฑูุฉ)
    db_parsers = [extract_parser, save_parser, tables_parser, stats_parser]
    for subparser in db_parsers:
        subparser.add_argument('--db-host', default='localhost', help='ุนููุงู ูุงุนุฏุฉ ุงูุจูุงูุงุช')
        subparser.add_argument('--db-port', type=int, default=3306, help='ูููุฐ ูุงุนุฏุฉ ุงูุจูุงูุงุช')
        subparser.add_argument('--db-user', default='root', help='ุงุณู ุงููุณุชุฎุฏู')
        subparser.add_argument('--db-password', help='ูููุฉ ูุฑูุฑ ูุงุนุฏุฉ ุงูุจูุงูุงุช')
        subparser.add_argument('--db-name', default='bms', help='ุงุณู ูุงุนุฏุฉ ุงูุจูุงูุงุช')
    
    # ุฅุนุฏุงุฏุงุช ุงูุชุญุณูู (ูุดุชุฑูุฉ)
    optimization_parsers = [extract_parser, save_parser, tables_parser, stats_parser, parity_parser]
    for subparser in optimization_parsers:
        # ุฅุนุฏุงุฏุงุช ุงูุงุณุชุฎุฑุงุฌ
        subparser.add_argument('--max-workers', type=int, default=4, 
                             help='ุนุฏุฏ ุงูุนูููุงุช ุงููุชูุงุฒูุฉ (ุงูุชุฑุงุถู: 4)')
        subparser.add_argument('--rate', type=float, default=2.0, 
                             help='ูุนุฏู ุงูุทูุจุงุช ูู ุงูุซุงููุฉ (ุงูุชุฑุงุถู: 2.0)')
        subparser.add_argument('--timeout', type=int, default=30, 
                             help='ูููุฉ ุงูุชุธุงุฑ ุงูุทูุจ ุจุงูุซูุงูู (ุงูุชุฑุงุถู: 30)')
        subparser.add_argument('--retries', type=int, default=3, 
                             help='ุนุฏุฏ ุงููุญุงููุงุช ุนูุฏ ุงููุดู (ุงูุชุฑุงุถู: 3)')
        subparser.add_argument('--chunk-size', type=int, default=100, 
                             help='ุญุฌู ุฏูุนุฉ ูุนุงูุฌุฉ ุงูุตูุญุงุช (ุงูุชุฑุงุถู: 100)')
        
        # ุฅุนุฏุงุฏุงุช ูุงุนุฏุฉ ุงูุจูุงูุงุช
        subparser.add_argument('--batch-size', type=int, default=500, 
                             help='ุญุฌู ุฏูุนุฉ ุงูุฅุฏุฑุงุฌ ูู ูุงุนุฏุฉ ุงูุจูุงูุงุช (ุงูุชุฑุงุถู: 500)')
        subparser.add_argument('--commit-interval', type=int, default=1000, 
                             help='ูุชุฑุฉ ุงูุชุฒุงู ุงููุนุงููุงุช (ุงูุชุฑุงุถู: 1000)')
        subparser.add_argument('--connection-pool-size', type=int, default=5, 
                             help='ุญุฌู ูุฌููุนุฉ ุงูุงุชุตุงูุงุช (ุงูุชุฑุงุถู: 5)')
        
        # ุฃุนูุงู ุงูุชุญุณูู
        subparser.add_argument('--stream-json', action='store_true', 
                             help='ุงุณุชุฎุฏุงู ุงูุญูุธ ุงููุญุณู ููุฐุงูุฑุฉ ูู JSON')
        subparser.add_argument('--resume', action='store_true', 
                             help='ุชูููู ุงูุงุณุชุฆูุงู ุงูุขูู ูู ููุงุท ุงูุชูุชูุด')
        subparser.add_argument('--skip-existing', action='store_true', 
                             help='ุชุฎุทู ุงูุนูุงุตุฑ ุงูููุฌูุฏุฉ')
        subparser.add_argument('--fast-bulk', action='store_true', 
                             help='ุชูููู ุงูุนูููุงุช ุงููุฌูุนุฉ ุงูุณุฑูุนุฉ (ุชุนุทูู ุงููููุฏ ูุคูุชุงู)')
        subparser.add_argument('--fail-fast', action='store_true', 
                             help='ุงูุชููู ุนูุฏ ุฃูู ุฎุทุฃ')
        
        # ุฅุนุฏุงุฏุงุช ุงูุณุฌูุงุช
        subparser.add_argument('--log-level', default='INFO', 
                             choices=['DEBUG', 'INFO', 'WARNING', 'ERROR'], 
                             help='ูุณุชูู ุงูุณุฌูุงุช (ุงูุชุฑุงุถู: INFO)')
    
    args = parser.parse_args()
    
    if not args.command:
        parser.print_help()
        return
    
    # ุฅุนุฏุงุฏ ุงูุณุฌูุงุช ุงููุญุณู
    setup_optimized_logging(args.log_level)
    
    # ุฅุนุฏุงุฏุงุช ูุงุนุฏุฉ ุงูุจูุงูุงุช
    db_config = None
    if hasattr(args, 'db_host') and any([args.db_host, args.db_user, args.db_password, args.db_name]):
        if not args.db_password:
            import getpass
            args.db_password = getpass.getpass("ูููุฉ ูุฑูุฑ ูุงุนุฏุฉ ุงูุจูุงูุงุช: ")
        
        db_config = {
            'host': args.db_host,
            'port': args.db_port,
            'user': args.db_user,
            'password': args.db_password,
            'database': args.db_name
        }
    
    # ุฅุนุฏุงุฏุงุช ุงูุชุญุณูู
    optimization_config = {
        'max_workers': args.max_workers,
        'rate': args.rate,
        'timeout': args.timeout,
        'retries': args.retries,
        'chunk_size': args.chunk_size,
        'batch_size': args.batch_size,
        'commit_interval': args.commit_interval,
        'connection_pool_size': args.connection_pool_size,
        'stream_json': args.stream_json,
        'resume': args.resume,
        'skip_existing': args.skip_existing,
        'fast_bulk': args.fast_bulk,
        'fail_fast': args.fail_fast
    }
    
    try:
        if args.command == 'extract':
            result = extract_and_save_book_optimized(
                args.book_id,
                max_pages=args.max_pages,
                db_config=db_config,
                output_dir=args.output_dir,
                optimization_config=optimization_config
            )
            
            if not result['success']:
                sys.exit(1)
        
        elif args.command == 'save-db':
            if not db_config:
                print("โ ุฎุทุฃ: ูุฌุจ ุชุญุฏูุฏ ุฅุนุฏุงุฏุงุช ูุงุนุฏุฉ ุงูุจูุงูุงุช")
                sys.exit(1)
            
            if not os.path.exists(args.json_file):
                print(f"โ ุฎุทุฃ: ุงูููู ุบูุฑ ููุฌูุฏ: {args.json_file}")
                sys.exit(1)
            
            result = save_to_database_optimized(args.json_file, db_config, optimization_config)
            
            if not result['success']:
                sys.exit(1)
        
        elif args.command == 'create-tables':
            if not db_config:
                print("โ ุฎุทุฃ: ูุฌุจ ุชุญุฏูุฏ ุฅุนุฏุงุฏุงุช ูุงุนุฏุฉ ุงูุจูุงูุงุช")
                sys.exit(1)
            
            result = create_database_tables_optimized(db_config, optimization_config)
            
            if not result['success']:
                sys.exit(1)
        
        elif args.command == 'stats':
            if not db_config:
                print("โ ุฎุทุฃ: ูุฌุจ ุชุญุฏูุฏ ุฅุนุฏุงุฏุงุช ูุงุนุฏุฉ ุงูุจูุงูุงุช")
                sys.exit(1)
            
            result = get_database_stats_optimized(args.book_id, db_config, optimization_config)
            
            if not result['success']:
                sys.exit(1)
        
        elif args.command == 'parity-check':
            result = run_parity_check(args.book_id, args.max_pages)
            
            if not result['success'] or not result.get('parity_check', False):
                sys.exit(1)
        
        print_separator()
        print("๐ ุชูุช ุงูุนูููุฉ ุจูุฌุงุญ!")
        
    except KeyboardInterrupt:
        print("\nโ ุชู ุฅูุบุงุก ุงูุนูููุฉ ุจูุงุณุทุฉ ุงููุณุชุฎุฏู")
        sys.exit(1)
    except Exception as e:
        logger.error(f"ุฎุทุฃ ุบูุฑ ูุชููุน: {e}")
        print(f"โ ุฎุทุฃ ุบูุฑ ูุชููุน: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()