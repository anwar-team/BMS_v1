#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Shamela Runner - Ø³ÙƒØ±Ø¨Øª ØªØ´ØºÙŠÙ„ Ø´Ø§Ù…Ù„ Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆØ­ÙØ¸ ÙƒØªØ¨ Ø§Ù„Ø´Ø§Ù…Ù„Ø©
ÙŠØ¬Ù…Ø¹ Ø¨ÙŠÙ† Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙƒØªØ¨ Ù…Ù† Ø§Ù„Ù…ÙˆÙ‚Ø¹ ÙˆØ­ÙØ¸Ù‡Ø§ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
"""

import os
import sys
import json
import logging
import argparse
from typing import Dict, Any, Optional
from datetime import datetime
from pathlib import Path

# Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø­Ø§Ù„ÙŠ Ù„Ù„Ù…Ø³Ø§Ø±
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

try:
    from shamela_complete_scraper import scrape_complete_book, save_book_to_json
    from shamela_database_manager import ShamelaDatabaseManager, save_json_to_database
except ImportError as e:
    print(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„ÙˆØ­Ø¯Ø§Øª: {e}")
    print("ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ù…Ù„ÙØ§Øª shamela_complete_scraper.py Ùˆ shamela_database_manager.py")
    sys.exit(1)

# Ø¥Ø¹Ø¯Ø§Ø¯ Ù†Ø¸Ø§Ù… Ø§Ù„Ø³Ø¬Ù„Ø§Øª
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('shamela_runner.log', encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

class ShamelaBatchProcessor:
    """Ù…Ø¹Ø§Ù„Ø¬ Ø¯ÙØ¹ÙŠ Ù„ÙƒØªØ¨ Ø§Ù„Ø´Ø§Ù…Ù„Ø©"""
    
    def __init__(self, output_dir: str = "shamela_books", db_config: Optional[Dict[str, Any]] = None):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        self.db_config = db_config
        self.processed_books = []
        self.failed_books = []
        
        # Ù…Ù„Ù Ù„Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø¯Ù…
        self.progress_file = self.output_dir / "progress.json"
        self.load_progress()
    
    def load_progress(self):
        """ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØªÙ‚Ø¯Ù… Ø§Ù„Ù…Ø­ÙÙˆØ¸"""
        if self.progress_file.exists():
            try:
                with open(self.progress_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    self.processed_books = data.get('processed', [])
                    self.failed_books = data.get('failed', [])
                logger.info(f"ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØªÙ‚Ø¯Ù…: {len(self.processed_books)} ÙƒØªØ§Ø¨ Ù…ÙƒØªÙ…Ù„ØŒ {len(self.failed_books)} ÙØ§Ø´Ù„")
            except Exception as e:
                logger.warning(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù Ø§Ù„ØªÙ‚Ø¯Ù…: {e}")
    
    def save_progress(self):
        """Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø¯Ù… Ø§Ù„Ø­Ø§Ù„ÙŠ"""
        try:
            progress_data = {
                'processed': self.processed_books,
                'failed': self.failed_books,
                'last_update': datetime.now().isoformat()
            }
            with open(self.progress_file, 'w', encoding='utf-8') as f:
                json.dump(progress_data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø­ÙØ¸ Ù…Ù„Ù Ø§Ù„ØªÙ‚Ø¯Ù…: {e}")
    
    def process_book(self, book_id: str, extract_html: bool = True, 
                    page_range: Optional[tuple] = None, save_to_db: bool = True) -> Dict[str, Any]:
        """Ù…Ø¹Ø§Ù„Ø¬Ø© ÙƒØªØ§Ø¨ ÙˆØ§Ø­Ø¯"""
        result = {
            'book_id': book_id,
            'success': False,
            'json_file': None,
            'db_saved': False,
            'error': None,
            'stats': {}
        }
        
        try:
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©
            if book_id in [b['book_id'] for b in self.processed_books]:
                logger.info(f"Ø§Ù„ÙƒØªØ§Ø¨ {book_id} ØªÙ… Ù…Ø¹Ø§Ù„Ø¬ØªÙ‡ Ù…Ø³Ø¨Ù‚Ø§Ù‹")
                result['success'] = True
                result['skipped'] = True
                return result
            
            logger.info(f"Ø¨Ø¯Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ÙƒØªØ§Ø¨: {book_id}")
            
            # 1. Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙƒØªØ§Ø¨
            book = scrape_complete_book(
                book_id=book_id,
                extract_html=extract_html,
                page_range=page_range
            )
            
            if not book:
                raise Exception("ÙØ´Ù„ ÙÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙƒØªØ§Ø¨")
            
            # 2. Ø­ÙØ¸ ÙÙŠ Ù…Ù„Ù JSON
            json_filename = f"book_{book_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            json_path = self.output_dir / json_filename
            
            save_book_to_json(book, str(json_path))
            result['json_file'] = str(json_path)
            
            # 3. Ø­ÙØ¸ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù…ØªÙˆÙØ±Ø©)
            if save_to_db and self.db_config:
                try:
                    db_result = save_json_to_database(str(json_path), self.db_config)
                    result['db_saved'] = True
                    result['db_stats'] = db_result
                    logger.info(f"ØªÙ… Ø­ÙØ¸ Ø§Ù„ÙƒØªØ§Ø¨ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {db_result['book_id']}")
                except Exception as db_error:
                    logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø­ÙØ¸ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {db_error}")
                    result['db_error'] = str(db_error)
            
            # 4. Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„ÙƒØªØ§Ø¨
            result['stats'] = {
                'title': book.title,
                'authors': [author.name for author in book.authors],
                'pages_count': len(book.pages),
                'chapters_count': len(book.index),
                'volumes_count': len(book.volumes),
                'total_words': sum(page.word_count or 0 for page in book.pages)
            }
            
            result['success'] = True
            self.processed_books.append(result)
            logger.info(f"ØªÙ… Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ÙƒØªØ§Ø¨ Ø¨Ù†Ø¬Ø§Ø­: {book.title}")
            
        except Exception as e:
            error_msg = str(e)
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ÙƒØªØ§Ø¨ {book_id}: {error_msg}")
            result['error'] = error_msg
            self.failed_books.append(result)
        
        finally:
            self.save_progress()
        
        return result
    
    def process_book_list(self, book_ids: list, extract_html: bool = True, 
                         save_to_db: bool = True, continue_on_error: bool = True) -> Dict[str, Any]:
        """Ù…Ø¹Ø§Ù„Ø¬Ø© Ù‚Ø§Ø¦Ù…Ø© Ù…Ù† Ø§Ù„ÙƒØªØ¨"""
        logger.info(f"Ø¨Ø¯Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© {len(book_ids)} ÙƒØªØ§Ø¨")
        
        results = {
            'total_books': len(book_ids),
            'successful': 0,
            'failed': 0,
            'skipped': 0,
            'books': []
        }
        
        for i, book_id in enumerate(book_ids, 1):
            logger.info(f"Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ÙƒØªØ§Ø¨ {i}/{len(book_ids)}: {book_id}")
            
            try:
                result = self.process_book(
                    book_id=book_id,
                    extract_html=extract_html,
                    save_to_db=save_to_db
                )
                
                results['books'].append(result)
                
                if result['success']:
                    if result.get('skipped'):
                        results['skipped'] += 1
                    else:
                        results['successful'] += 1
                else:
                    results['failed'] += 1
                
                # Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„ØªÙ‚Ø¯Ù…
                logger.info(f"Ø§Ù„ØªÙ‚Ø¯Ù…: {results['successful']} Ù†Ø¬Ø­ØŒ {results['failed']} ÙØ´Ù„ØŒ {results['skipped']} ØªÙ… ØªØ®Ø·ÙŠÙ‡")
                
            except Exception as e:
                logger.error(f"Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ÙƒØªØ§Ø¨ {book_id}: {e}")
                results['failed'] += 1
                
                if not continue_on_error:
                    logger.error("ØªÙˆÙ‚Ù Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¨Ø³Ø¨Ø¨ Ø§Ù„Ø®Ø·Ø£")
                    break
        
        # Ø­ÙØ¸ ØªÙ‚Ø±ÙŠØ± Ù†Ù‡Ø§Ø¦ÙŠ
        report_file = self.output_dir / f"batch_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        logger.info(f"Ø§Ù†ØªÙ‡Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¯ÙØ¹ÙŠØ©. Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ù…Ø­ÙÙˆØ¸ ÙÙŠ: {report_file}")
        return results
    
    def retry_failed_books(self, extract_html: bool = True, save_to_db: bool = True) -> Dict[str, Any]:
        """Ø¥Ø¹Ø§Ø¯Ø© Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„ÙƒØªØ¨ Ø§Ù„ÙØ§Ø´Ù„Ø©"""
        failed_ids = [book['book_id'] for book in self.failed_books]
        
        if not failed_ids:
            logger.info("Ù„Ø§ ØªÙˆØ¬Ø¯ ÙƒØªØ¨ ÙØ§Ø´Ù„Ø© Ù„Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©")
            return {'message': 'Ù„Ø§ ØªÙˆØ¬Ø¯ ÙƒØªØ¨ ÙØ§Ø´Ù„Ø©'}
        
        logger.info(f"Ø¥Ø¹Ø§Ø¯Ø© Ù…Ø­Ø§ÙˆÙ„Ø© {len(failed_ids)} ÙƒØªØ§Ø¨ ÙØ§Ø´Ù„")
        
        # Ù…Ø³Ø­ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„ÙØ§Ø´Ù„Ø© Ù„Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©
        self.failed_books = []
        
        return self.process_book_list(
            book_ids=failed_ids,
            extract_html=extract_html,
            save_to_db=save_to_db
        )

def load_book_ids_from_file(file_path: str) -> list:
    """ØªØ­Ù…ÙŠÙ„ Ù‚Ø§Ø¦Ù…Ø© Ù…Ø¹Ø±ÙØ§Øª Ø§Ù„ÙƒØªØ¨ Ù…Ù† Ù…Ù„Ù"""
    book_ids = []
    
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#'):
                    # Ø¯Ø¹Ù… ØªÙ†Ø³ÙŠÙ‚Ø§Øª Ù…Ø®ØªÙ„ÙØ©
                    if line.isdigit():
                        book_ids.append(line)
                    elif 'shamela.ws/book/' in line:
                        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ø¹Ø±Ù Ù…Ù† Ø§Ù„Ø±Ø§Ø¨Ø·
                        parts = line.split('/')
                        for part in parts:
                            if part.isdigit():
                                book_ids.append(part)
                                break
    except Exception as e:
        logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù Ù…Ø¹Ø±ÙØ§Øª Ø§Ù„ÙƒØªØ¨: {e}")
        raise
    
    return book_ids

def parse_page_range(range_str: str) -> tuple:
    """ØªØ­Ù„ÙŠÙ„ Ù†Ø·Ø§Ù‚ Ø§Ù„ØµÙØ­Ø§Øª Ù…Ù† Ù†Øµ"""
    if not range_str:
        return None
    
    try:
        if '-' in range_str:
            start, end = range_str.split('-', 1)
            return (int(start.strip()), int(end.strip()))
        else:
            page = int(range_str.strip())
            return (page, page)
    except ValueError:
        raise ValueError(f"ØªÙ†Ø³ÙŠÙ‚ Ù†Ø·Ø§Ù‚ Ø§Ù„ØµÙØ­Ø§Øª ØºÙŠØ± ØµØ­ÙŠØ­: {range_str}")

def main():
    """Ø§Ù„ÙˆØ¸ÙŠÙØ© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©"""
    parser = argparse.ArgumentParser(
        description="Ø³ÙƒØ±Ø¨Øª Ø´Ø§Ù…Ù„ Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆØ­ÙØ¸ ÙƒØªØ¨ Ø§Ù„Ø´Ø§Ù…Ù„Ø©",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Ø£Ù…Ø«Ù„Ø© Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…:

# Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙƒØªØ§Ø¨ ÙˆØ§Ø­Ø¯:
python shamela_runner.py single 12345

# Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙƒØªØ§Ø¨ ÙˆØ­ÙØ¸Ù‡ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:
python shamela_runner.py single 12345 --save-db --db-password mypass

# Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¹Ø¯Ø© ÙƒØªØ¨ Ù…Ù† Ù…Ù„Ù:
python shamela_runner.py batch --book-list books.txt

# Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù†Ø·Ø§Ù‚ ØµÙØ­Ø§Øª Ù…Ø­Ø¯Ø¯:
python shamela_runner.py single 12345 --page-range "1-50"

# Ø¥Ø¹Ø§Ø¯Ø© Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„ÙƒØªØ¨ Ø§Ù„ÙØ§Ø´Ù„Ø©:
python shamela_runner.py retry
        """
    )
    
    subparsers = parser.add_subparsers(dest='command', help='Ø§Ù„Ø£ÙˆØ§Ù…Ø± Ø§Ù„Ù…ØªØ§Ø­Ø©')
    
    # Ø£Ù…Ø± Ù…Ø¹Ø§Ù„Ø¬Ø© ÙƒØªØ§Ø¨ ÙˆØ§Ø­Ø¯
    single_parser = subparsers.add_parser('single', help='Ù…Ø¹Ø§Ù„Ø¬Ø© ÙƒØªØ§Ø¨ ÙˆØ§Ø­Ø¯')
    single_parser.add_argument('book_id', help='Ù…Ø¹Ø±Ù Ø§Ù„ÙƒØªØ§Ø¨ ÙÙŠ Ø§Ù„Ø´Ø§Ù…Ù„Ø©')
    single_parser.add_argument('--page-range', help='Ù†Ø·Ø§Ù‚ Ø§Ù„ØµÙØ­Ø§Øª (Ù…Ø«Ø§Ù„: 1-50 Ø£Ùˆ 25)')
    
    # Ø£Ù…Ø± Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¯ÙØ¹ÙŠØ©
    batch_parser = subparsers.add_parser('batch', help='Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¯ÙØ¹ÙŠØ© Ù„Ù„ÙƒØªØ¨')
    batch_parser.add_argument('--book-list', help='Ù…Ù„Ù ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù‚Ø§Ø¦Ù…Ø© Ù…Ø¹Ø±ÙØ§Øª Ø§Ù„ÙƒØªØ¨')
    batch_parser.add_argument('--book-ids', nargs='+', help='Ù‚Ø§Ø¦Ù…Ø© Ù…Ø¹Ø±ÙØ§Øª Ø§Ù„ÙƒØªØ¨')
    batch_parser.add_argument('--continue-on-error', action='store_true', 
                             help='Ø§Ù„Ù…ØªØ§Ø¨Ø¹Ø© Ø¹Ù†Ø¯ Ø­Ø¯ÙˆØ« Ø®Ø·Ø£')
    
    # Ø£Ù…Ø± Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©
    retry_parser = subparsers.add_parser('retry', help='Ø¥Ø¹Ø§Ø¯Ø© Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„ÙƒØªØ¨ Ø§Ù„ÙØ§Ø´Ù„Ø©')
    
    # Ø®ÙŠØ§Ø±Ø§Øª Ù…Ø´ØªØ±ÙƒØ©
    for p in [single_parser, batch_parser, retry_parser]:
        p.add_argument('--output-dir', default='shamela_books', 
                      help='Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬ (Ø§ÙØªØ±Ø§Ø¶ÙŠ: shamela_books)')
        p.add_argument('--no-html', action='store_true', 
                      help='Ø¹Ø¯Ù… Ø§Ø³ØªØ®Ø±Ø§Ø¬ HTML Ù„Ù„ØµÙØ­Ø§Øª')
        p.add_argument('--save-db', action='store_true', 
                      help='Ø­ÙØ¸ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª')
        
        # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        p.add_argument('--db-host', default='localhost', help='Ø¹Ù†ÙˆØ§Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª')
        p.add_argument('--db-port', type=int, default=3306, help='Ù…Ù†ÙØ° Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª')
        p.add_argument('--db-user', default='root', help='Ø§Ø³Ù… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…')
        p.add_argument('--db-password', help='ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±')
        p.add_argument('--db-name', default='bms', help='Ø§Ø³Ù… Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª')
    
    args = parser.parse_args()
    
    if not args.command:
        parser.print_help()
        return
    
    # Ø¥Ø¹Ø¯Ø§Ø¯ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    db_config = None
    if args.save_db:
        db_password = args.db_password
        if not db_password:
            import getpass
            db_password = getpass.getpass("ÙƒÙ„Ù…Ø© Ù…Ø±ÙˆØ± Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: ")
        
        db_config = {
            'host': args.db_host,
            'port': args.db_port,
            'user': args.db_user,
            'password': db_password,
            'database': args.db_name
        }
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬
    processor = ShamelaBatchProcessor(
        output_dir=args.output_dir,
        db_config=db_config
    )
    
    try:
        if args.command == 'single':
            # Ù…Ø¹Ø§Ù„Ø¬Ø© ÙƒØªØ§Ø¨ ÙˆØ§Ø­Ø¯
            page_range = parse_page_range(args.page_range) if hasattr(args, 'page_range') and args.page_range else None
            
            result = processor.process_book(
                book_id=args.book_id,
                extract_html=not args.no_html,
                page_range=page_range,
                save_to_db=args.save_db
            )
            
            if result['success']:
                print(f"âœ… ØªÙ… Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ÙƒØªØ§Ø¨ Ø¨Ù†Ø¬Ø§Ø­: {result['stats'].get('title', args.book_id)}")
                print(f"ğŸ“„ Ø¹Ø¯Ø¯ Ø§Ù„ØµÙØ­Ø§Øª: {result['stats'].get('pages_count', 0)}")
                print(f"ğŸ“š Ø¹Ø¯Ø¯ Ø§Ù„ÙØµÙˆÙ„: {result['stats'].get('chapters_count', 0)}")
                print(f"ğŸ’¾ Ù…Ù„Ù JSON: {result['json_file']}")
                if result.get('db_saved'):
                    print(f"ğŸ—„ï¸ ØªÙ… Ø§Ù„Ø­ÙØ¸ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
            else:
                print(f"âŒ ÙØ´Ù„ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ÙƒØªØ§Ø¨: {result['error']}")
                sys.exit(1)
        
        elif args.command == 'batch':
            # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¯ÙØ¹ÙŠØ©
            book_ids = []
            
            if args.book_list:
                book_ids.extend(load_book_ids_from_file(args.book_list))
            
            if args.book_ids:
                book_ids.extend(args.book_ids)
            
            if not book_ids:
                print("Ø®Ø·Ø£: ÙŠØ¬Ø¨ ØªØ­Ø¯ÙŠØ¯ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„ÙƒØªØ¨ Ø¹Ø¨Ø± --book-list Ø£Ùˆ --book-ids")
                sys.exit(1)
            
            results = processor.process_book_list(
                book_ids=book_ids,
                extract_html=not args.no_html,
                save_to_db=args.save_db,
                continue_on_error=args.continue_on_error
            )
            
            print(f"\nğŸ“Š Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¯ÙØ¹ÙŠØ©:")
            print(f"ğŸ“š Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„ÙƒØªØ¨: {results['total_books']}")
            print(f"âœ… Ù†Ø¬Ø­: {results['successful']}")
            print(f"âŒ ÙØ´Ù„: {results['failed']}")
            print(f"â­ï¸ ØªÙ… ØªØ®Ø·ÙŠÙ‡: {results['skipped']}")
        
        elif args.command == 'retry':
            # Ø¥Ø¹Ø§Ø¯Ø© Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„ÙƒØªØ¨ Ø§Ù„ÙØ§Ø´Ù„Ø©
            results = processor.retry_failed_books(
                extract_html=not args.no_html,
                save_to_db=args.save_db
            )
            
            if 'message' in results:
                print(results['message'])
            else:
                print(f"\nğŸ“Š Ù†ØªØ§Ø¦Ø¬ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©:")
                print(f"ğŸ“š Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„ÙƒØªØ¨: {results['total_books']}")
                print(f"âœ… Ù†Ø¬Ø­: {results['successful']}")
                print(f"âŒ ÙØ´Ù„: {results['failed']}")
    
    except KeyboardInterrupt:
        logger.info("ØªÙ… Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ø¨ÙˆØ§Ø³Ø·Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…")
        print("\nâ¹ï¸ ØªÙ… Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ø¹Ù…Ù„ÙŠØ©")
    except Exception as e:
        logger.error(f"Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹: {e}")
        print(f"âŒ Ø®Ø·Ø£: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()